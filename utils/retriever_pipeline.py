import streamlit as st
from utils.build_graph import retrieve_from_graph
from langchain_core.documents import Document
import requests
import os
from dotenv import load_dotenv
import openai

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


def expand_query(query, uri=None, model="gpt-3.5-turbo"):
    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[{"role": "user", "content": f"Gi·∫£ s·ª≠ b·∫°n ƒë√£ c√≥ c√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi sau. H√£y t·∫°o c√¢u tr·∫£ l·ªùi h·ª£p l√Ω nh·∫•t c√≥ th·ªÉ ƒë·ªÉ d√πng cho t√¨m ki·∫øm th√¥ng tin:\n\n{query}"}],
            temperature=0.5
        )
        hypothetical_answer = response.choices[0].message["content"]
        return f"{query}\n{hypothetical_answer}"
    except Exception as e:
        st.error(f"‚ùå HyDE failed: {str(e)}")
        return query




def retrieve_documents(query, uri, model, chat_history=""):
    
    expanded_query = expand_query(f"{chat_history}\n{query}", uri, model) 

    if st.session_state.enable_hyde:
        expanded_query = expand_query(f"{chat_history}\n{query}", uri, model)
        st.session_state.hyde_query = expanded_query
    else:
        expanded_query = query
        st.session_state.hyde_query = None

    docs = st.session_state.retrieval_pipeline["ensemble"].invoke(expanded_query)

    if st.session_state.enable_graph_rag:
        G = st.session_state.retrieval_pipeline.get("knowledge_graph")
        graph_results = retrieve_from_graph(query, G)

        st.write(f"üß† GraphRAG tr·∫£ v·ªÅ c√°c n√∫t li√™n quan: {graph_results}")

        graph_docs = [Document(page_content=node) for node in graph_results]

        if graph_docs:
            docs = graph_docs + docs


    if st.session_state.enable_reranking:
        pairs = [[query, doc.page_content] for doc in docs]
        scores = st.session_state.retrieval_pipeline["reranker"].predict(pairs)


        ranked_docs = [doc for _, doc in sorted(zip(scores, docs), reverse=True)]
    else:
        ranked_docs = docs

    return ranked_docs[:st.session_state.max_contexts]
